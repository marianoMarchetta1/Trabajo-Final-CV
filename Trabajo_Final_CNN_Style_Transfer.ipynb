{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo_Final_CNN_Style_Transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHsa2t0SxZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffcf7b4-0481-4ff7-c479-29124ebe8585"
      },
      "source": [
        "# Imagen para estilo\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
        "\n",
        "# Creamos el directorio para los archivos de salida\n",
        "!mkdir /content/output"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-27 19:45:34--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223725 (218K) [image/jpeg]\n",
            "Saving to: ‘La_noche_estrellada1.jpg.3’\n",
            "\n",
            "La_noche_estrellada 100%[===================>] 218.48K  1.39MB/s    in 0.2s    \n",
            "\n",
            "2022-04-27 19:45:35 (1.39 MB/s) - ‘La_noche_estrellada1.jpg.3’ saved [223725/223725]\n",
            "\n",
            "--2022-04-27 19:45:35--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 153015 (149K) [image/jpeg]\n",
            "Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.3’\n",
            "\n",
            "775px-Neckarfront_T 100%[===================>] 149.43K   990KB/s    in 0.2s    \n",
            "\n",
            "2022-04-27 19:45:35 (990 KB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.3’ saved [153015/153015]\n",
            "\n",
            "mkdir: cannot create directory ‘/content/output’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIxH20o2eFoc"
      },
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "base_image_path = Path(\"/content/bariloche.jpeg\")\n",
        "style_reference_image_path = Path(\"/content/929px-Starry_Night_Over_the_Rhone.webp\")\n",
        "result_prefix = Path(\"/content/output6\")\n",
        "iterations = 100"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "Respuesta: \n",
        "\n",
        "*   total_variation_weight: peso utlizado en el calculo de la loss y es encargado de penalizar la varianza de la imagen generada dandole coherencia y suavidad en los cambios entre pixeles\n",
        "\n",
        "*   style_weight (alfa): define la importancia de respetar los estilos de la imagen que aporta estilos (valga la redundancia) al momento de calcular el loss.\n",
        "\n",
        "*   content_weight (beta): define la importancia de respetar la forma de la imagen que aporta contenido.\n",
        "\n",
        "Entre estos dos parametros (alfa y beta) vamos a tener un trade-off entre contenido y estilo.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Ltotal(~p,~a, ~x) = αLcontent(~p, ~x) + βLstyle(~a, ~x) \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "source": [
        "total_variation_weight = 0.3\n",
        "style_weight = 10\n",
        "content_weight = 5"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "source": [
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
        "\n",
        "Ayuda: https://keras.io/applications/\n",
        "\n",
        "Respuesta: \n",
        "\n",
        "- Carga la imagen y la redimenciona para adecularla al modelo (VGG19).\n",
        "- Convierte la imagen a un numpy array.\n",
        "- Expande el array de la linea anterior en 1 dimension para usarlo como input de la red.\n",
        "- Adecua la imagen (el array que la representa) a los requerimientos del modelo (VGG19), es decir, la convierte de RGB a BGR. Luego cada canal de color se centra en cero con respecto al dataset de ImageNet, sin escalado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "Respuesta: Realiza el proceso inverso, descentrando la imagen y convirtiendola a RGB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNio09mu4S3"
      },
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Lbw02Uu--o"
      },
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdG59VRavHGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2590ff95-6639-4b76-dcd0-914561bbc604"
      },
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
        "\n",
        "La matrix de Gram es el producto punto entre filtros, permite estimar la relacion entre los filtros de los diferentes layers y obtener cual es la correlacion entre ellos.\n",
        "Es utilizado para calcular el Style Loss (de forma tal que se mantenga la correlacion de los estilos. EX: Circulos que se ven en la imagen C de la pagina 5 del paper).\n",
        "\n",
        "- ¿Por qué se permutan las dimensiones de x?\n",
        "\n",
        "De esta forma se permite encontrar aquellos features que se activan simultaneamente en una misma posicion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "Rta:\n",
        "\n",
        "*   style_loss: Consisten en utilizar la Gram Matrix generada entre la imagen original y la imagen generada para compararlas y determinar que tan bien nuestra red esta replicando el estilo de la imagen original, de forma tal que al minimizar esta diferencia, obtendremos una imagen cuyo estilo (texturas/colores) sea lo mas cercano a la imagen original posible.\n",
        "\n",
        "*   content_loss: Mide la distancia L2 de los features geneados por la red y los features de la content image base, para que al minimizar esta distancia, obtenegamos una imagen cuyo contenido sea lo mas parecido a la imagen real posible.\n",
        "\n",
        "*   total_variation_loss: Mide la transicion entre pixeles de la imagen generada, permitiendo genear una transicion suave al ser minimizado. Permite mantener la coherencia y continuidad espacial del output de la red. Genera un efecto normalizador, no es parte del paper original.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ],
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :] \n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbz4n1OhvV2K"
      },
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ],
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "*   Primer celda: Funcion utilizada para la evaluacion del loss y el gadiente.\n",
        "\n",
        "*   Segunda celda: Define una clase llamada Evaluator(), encargada de calcular el loss y los grads de forma simultanea para realizar el proceso de una forma mas eficiente (debido que el optimizado utilizado, L-BFGS, requiere que se calculen en funciones separadas).\n",
        "\n",
        "*   Tercer celda: Loop del optimizador. Se itera n veces, 100 en este caso. Por cada loop se calcula la loss y se actualizan los pesos a partir de los gradientes, se deprocesa la imagen (punto 3 de este trabajo) y se guarda el resultado como resultado de la interacion para su posterior visualizacion.\n",
        "\n",
        "\n",
        "El paper define la utilizacion del Style Loss y el Content Loss, mientras que en este trabajo se utiliza tambien el Total Variation Loss.\n",
        "\n",
        "Un metodo alternativo, podria ser utilizar otro optimizador como SGD o Adam."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31YBwCVvhAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b150022e-63f0-493e-b7a1-b1febf1c24f2"
      },
      "source": [
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 27832705000.0\n",
            "Image saved as /content/output6/output_at_iteration_0.png\n",
            "Iteration 0 completed in 20s\n",
            "Start of iteration 1\n",
            "Current loss value: 15226663000.0\n",
            "Image saved as /content/output6/output_at_iteration_1.png\n",
            "Iteration 1 completed in 18s\n",
            "Start of iteration 2\n",
            "Current loss value: 11657843000.0\n",
            "Image saved as /content/output6/output_at_iteration_2.png\n",
            "Iteration 2 completed in 18s\n",
            "Start of iteration 3\n",
            "Current loss value: 9536422000.0\n",
            "Image saved as /content/output6/output_at_iteration_3.png\n",
            "Iteration 3 completed in 18s\n",
            "Start of iteration 4\n",
            "Current loss value: 8426078700.0\n",
            "Image saved as /content/output6/output_at_iteration_4.png\n",
            "Iteration 4 completed in 18s\n",
            "Start of iteration 5\n",
            "Current loss value: 7595171300.0\n",
            "Image saved as /content/output6/output_at_iteration_5.png\n",
            "Iteration 5 completed in 18s\n",
            "Start of iteration 6\n",
            "Current loss value: 7087392300.0\n",
            "Image saved as /content/output6/output_at_iteration_6.png\n",
            "Iteration 6 completed in 18s\n",
            "Start of iteration 7\n",
            "Current loss value: 6671596500.0\n",
            "Image saved as /content/output6/output_at_iteration_7.png\n",
            "Iteration 7 completed in 18s\n",
            "Start of iteration 8\n",
            "Current loss value: 6374812000.0\n",
            "Image saved as /content/output6/output_at_iteration_8.png\n",
            "Iteration 8 completed in 19s\n",
            "Start of iteration 9\n",
            "Current loss value: 6138878000.0\n",
            "Image saved as /content/output6/output_at_iteration_9.png\n",
            "Iteration 9 completed in 18s\n",
            "Start of iteration 10\n",
            "Current loss value: 5961158000.0\n",
            "Image saved as /content/output6/output_at_iteration_10.png\n",
            "Iteration 10 completed in 18s\n",
            "Start of iteration 11\n",
            "Current loss value: 5738959000.0\n",
            "Image saved as /content/output6/output_at_iteration_11.png\n",
            "Iteration 11 completed in 18s\n",
            "Start of iteration 12\n",
            "Current loss value: 5582214000.0\n",
            "Image saved as /content/output6/output_at_iteration_12.png\n",
            "Iteration 12 completed in 18s\n",
            "Start of iteration 13\n",
            "Current loss value: 5477134300.0\n",
            "Image saved as /content/output6/output_at_iteration_13.png\n",
            "Iteration 13 completed in 18s\n",
            "Start of iteration 14\n",
            "Current loss value: 5393869000.0\n",
            "Image saved as /content/output6/output_at_iteration_14.png\n",
            "Iteration 14 completed in 18s\n",
            "Start of iteration 15\n",
            "Current loss value: 5317419000.0\n",
            "Image saved as /content/output6/output_at_iteration_15.png\n",
            "Iteration 15 completed in 18s\n",
            "Start of iteration 16\n",
            "Current loss value: 5218153500.0\n",
            "Image saved as /content/output6/output_at_iteration_16.png\n",
            "Iteration 16 completed in 18s\n",
            "Start of iteration 17\n",
            "Current loss value: 5143105000.0\n",
            "Image saved as /content/output6/output_at_iteration_17.png\n",
            "Iteration 17 completed in 18s\n",
            "Start of iteration 18\n",
            "Current loss value: 5054411000.0\n",
            "Image saved as /content/output6/output_at_iteration_18.png\n",
            "Iteration 18 completed in 18s\n",
            "Start of iteration 19\n",
            "Current loss value: 4988247000.0\n",
            "Image saved as /content/output6/output_at_iteration_19.png\n",
            "Iteration 19 completed in 18s\n",
            "Start of iteration 20\n",
            "Current loss value: 4934053400.0\n",
            "Image saved as /content/output6/output_at_iteration_20.png\n",
            "Iteration 20 completed in 18s\n",
            "Start of iteration 21\n",
            "Current loss value: 4879781000.0\n",
            "Image saved as /content/output6/output_at_iteration_21.png\n",
            "Iteration 21 completed in 18s\n",
            "Start of iteration 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "Respuesta: Se probo con la siguiente combinacion de pesos (imagenes adjuntas en carpeta con nombre \"Punto 8\"):\n",
        "\n",
        "*   style_weight = 10 ; content_weight = 1 ; total_variation_weight = 0.1\n",
        "*   style_weight = 1 ; content_weight = 10 ; total_variation_weight = 0.1\n",
        "*   style_weight = 10 ; content_weight = 1 ; total_variation_weight = 0.8\n",
        "*   style_weight = 10 ; content_weight = 10 ; total_variation_weight = 0.1\n",
        "*   style_weight = 10 ; content_weight = 1 ; total_variation_weight = 5\n",
        "\n",
        "De estos casos de prueba, podemos concluir notar algunas cosas a destacar:\n",
        "\n",
        "* Al darle mas peso al content_weight se pierden menos detalles de la foto original (Podremos observar esto si comparamos la imagen final de la prueba 1 y la prueba 2, particularmente observando las sombras dentro del agua o los detalles en el techo de la primer casa de izquierda a derecha).\n",
        "\n",
        "* Al darle mas peso al style_weight mantenemos unos estilos mas fieles a la imagen de estilo (Podremos observar esto comparando la imagen final de la prueba 1 y la prueba 2, particularmente en los circulos amarillentos que se visualizan en el cielo sobre la imagen 2 y que tambien se encuentran presentes en la imagen de estilo pero no en la imagen que resulta de la prueba 1).\n",
        "\n",
        "* Al darle mas peso a total_variation_weight obtendremos una imagen donde la transicion entre los elementos de la imagen sea mas amena (Se realizo primero la prueba 3 utilizando como valor 0.8, pero al no visualizar grandes cambios se relaizo luego la prueba 5 con un valor de 5 para este weight. Aqui podemos observar cierta continuidad entre los bordes de las casas, e incluso hay una en aprticular donde se puede ver que los colores amarillo y violeta se entrelazan. Tambien la imagen parece haber ganado cierto brillo o contraste).\n",
        "\n",
        "* Al mantener mismos valores para style_weight y content_weight obtendremos un punto medio entre la variacion de los estilos y la deformacion de la imagen (esto se puede visualizar en la prueba 4, donde ambos valores fueron seteados en 5, y el resultado final es una imagen que encuentra cierto equilibrio entre los primeros dos items destacados mas arriba. Por ejemplo, las sombras del agua estan mas visibles que en el punto dos, pero no tanto como el puto 1. Esto mismo pasa con los circulos del cielo).\n",
        "\n",
        "\n",
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta: Imagenes adjuntadas en la carpeta Punto 9"
      ]
    }
  ]
}